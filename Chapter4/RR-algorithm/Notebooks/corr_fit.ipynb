{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Pierre-Paul\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Pierre-Paul\\Anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "C:\\Users\\Pierre-Paul\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\Pierre-Paul\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\Pierre-Paul\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import multiprocessing as mp\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "df = pd.read_pickle('df_S300_featurized')\n",
    "df = df.replace([np.inf, -np.inf, np.nan], 0)\n",
    "df_X = df.drop('Input Data|S_300_atom',axis=1)\n",
    "a = {}\n",
    "for x in df_X.columns:\n",
    "    if 'ChemEnvSiteFingerprint|GaussianSymmFunc' in x:\n",
    "        a[x] = 'GaussianSymmFunc|'+x[39:]\n",
    "df_X = df_X.rename(a,axis=1)\n",
    "\n",
    "df_Y = df[['Input Data|S_300_atom']]\n",
    "\n",
    "df_X=(df_X-df_X.min())/(df_X.max()-df_X.min())\n",
    "#df_Y=(df_Y-df_Y.min())/(df_Y.max()-df_Y.min())\n",
    "df_X = df_X.replace([np.inf, -np.inf, np.nan], 0)\n",
    "\n",
    "f_test,_ = f_regression(df_X,df_Y)\n",
    "\n",
    "def get_features(n):\n",
    "    \n",
    "    n_best = f_test.argsort()[-n:]\n",
    "    \n",
    "    return df_X.columns[n_best]\n",
    "\n",
    "def CV_NN(model,df_X,df_Y,cv=5,epochs=200,batch_size=100,plot = False):\n",
    "  df_X,df_Y = shuffle(df_X,df_Y)\n",
    "  size = df_X.shape[0]\n",
    "  mae_score = np.zeros(cv)\n",
    "  map_score = np.zeros(cv)\n",
    "  \n",
    "  weights = model.get_weights()\n",
    "  \n",
    "  for i in range(cv):\n",
    "    fit_params = {\n",
    "            'x': df_X.values,\n",
    "            'y': df_Y.values,\n",
    "            'epochs': epochs+20,\n",
    "            'batch_size': batch_size,\n",
    "            'verbose': 0,\n",
    "            'validation_split' : 1/cv\n",
    "    }\n",
    "    \n",
    "    model.set_weights(weights)\n",
    "    history = model.fit(**fit_params)\n",
    "    mae =  history.history['mean_absolute_error']\n",
    "    val_map = history.history['val_mean_absolute_percentage_error']\n",
    "    val_mae = history.history['val_mean_absolute_error']   \n",
    "    #score = np.sort(val_mae)[:40].mean()\n",
    "    #score_p = np.sort(val_map)[:40].mean()\n",
    "    score = np.array(val_mae[-40:]).mean()\n",
    "    score_p = np.array(val_map[-40:]).mean()\n",
    "    mae_score[i] = score\n",
    "    map_score[i] = score_p\n",
    "    temp = df_X.iloc[:size//cv,:]\n",
    "    idx = temp.index\n",
    "    df_X = df_X.drop(idx,axis=0)\n",
    "    df_X = df_X.append(temp)\n",
    "    temp = df_Y.loc[idx,:]\n",
    "    df_Y = df_Y.drop(idx,axis=0)\n",
    "    df_Y = df_Y.append(temp)\n",
    "    if plot:\n",
    "      fig, ax = plt.subplots(figsize=(6,6))\n",
    "      ax.plot(mae,label='mae')\n",
    "      ax.plot(val_mae,label='val_mae')\n",
    "      # ax.set_ylim([0,6])\n",
    "      ax.set_title('entropy @ 300K')\n",
    "      ax.set_ylabel('MAE [J/Kmol]')\n",
    "      ax.set_ylabel('epochs')\n",
    "      ax.legend()\n",
    "      #fig.savefig(\"e{}.jpg\".format(str(T)))\n",
    "      ax.grid()\n",
    "      \n",
    "  return (mae_score.mean(), map_score.mean())\n",
    "\n",
    "def gen_model(n_features,bias=2):\n",
    "    f_input = Input(shape=(n_features,))\n",
    "    hidden1 = Dense(int(n_features/2)+bias,activation='relu')(f_input)\n",
    "    #hidden2 = Dense(int(n_features/2)+2,activation='relu')(hidden1)\n",
    "    out = Dense(1,activation='linear')(hidden1) #output is bounded below\n",
    "    model = keras.models.Model(f_input,out)\n",
    "    model.compile(loss = 'mae', metrics=['mae','mean_absolute_percentage_error'],\n",
    "                  optimizer=keras.optimizers.Adam(0.01))\n",
    "    return model\n",
    "  \n",
    "    \n",
    "def grid_search(df_X,df_Y,n_features):\n",
    "    iterations = len(n_features)\n",
    "    i=1\n",
    "    mae_score = []\n",
    "    map_score = []\n",
    "    for n in n_features:\n",
    "        print('{}/{}'.format(i,iterations))\n",
    "        features = get_features(n)\n",
    "        X = df_X[features]\n",
    "        Y = df_Y\n",
    "        model = gen_model(n,bias=16)\n",
    "        best_score, best_scorep = CV_NN(model,X,Y)\n",
    "        print(\"{} features, {:.2f}% map/ {:.2f} mae\".format(n,best_scorep,best_score))\n",
    "        mae_score += [best_score]\n",
    "        map_score += [best_scorep]\n",
    "        i+=1\n",
    "    return (mae_score,map_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/38\n",
      "WARNING:tensorflow:From C:\\Users\\Pierre-Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Pierre-Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "2 features, 60.16% map/ 11.07 mae\n",
      "2/38\n",
      "3 features, 60.10% map/ 11.09 mae\n",
      "3/38\n",
      "4 features, 60.20% map/ 11.10 mae\n",
      "4/38\n",
      "5 features, 59.73% map/ 11.06 mae\n",
      "5/38\n",
      "6 features, 59.76% map/ 11.06 mae\n",
      "6/38\n",
      "7 features, 59.89% map/ 11.04 mae\n",
      "7/38\n",
      "8 features, 59.91% map/ 11.06 mae\n",
      "8/38\n",
      "9 features, 59.71% map/ 11.09 mae\n",
      "9/38\n",
      "10 features, 59.90% map/ 11.04 mae\n",
      "10/38\n",
      "12 features, 59.83% map/ 11.06 mae\n",
      "11/38\n",
      "14 features, 60.13% map/ 11.09 mae\n",
      "12/38\n",
      "16 features, 59.30% map/ 11.06 mae\n",
      "13/38\n",
      "18 features, 59.91% map/ 11.09 mae\n",
      "14/38\n",
      "20 features, 60.12% map/ 11.05 mae\n",
      "15/38\n",
      "24 features, 60.09% map/ 11.06 mae\n",
      "16/38\n",
      "28 features, 59.91% map/ 11.10 mae\n",
      "17/38\n",
      "32 features, 59.72% map/ 11.06 mae\n",
      "18/38\n",
      "35 features, 60.21% map/ 11.08 mae\n",
      "19/38\n",
      "40 features, 59.52% map/ 11.06 mae\n",
      "20/38\n",
      "45 features, 60.04% map/ 11.08 mae\n",
      "21/38\n",
      "50 features, 59.83% map/ 11.08 mae\n",
      "22/38\n",
      "55 features, 60.33% map/ 11.09 mae\n",
      "23/38\n",
      "60 features, 60.04% map/ 11.06 mae\n",
      "24/38\n",
      "70 features, 59.54% map/ 11.05 mae\n",
      "25/38\n",
      "80 features, 59.60% map/ 11.04 mae\n",
      "26/38\n",
      "90 features, 59.98% map/ 11.08 mae\n",
      "27/38\n",
      "100 features, 60.10% map/ 11.06 mae\n",
      "28/38\n",
      "150 features, 59.47% map/ 11.05 mae\n",
      "29/38\n",
      "200 features, 59.60% map/ 11.07 mae\n",
      "30/38\n",
      "250 features, 59.66% map/ 11.05 mae\n",
      "31/38\n",
      "300 features, 59.99% map/ 11.08 mae\n",
      "32/38\n",
      "400 features, 60.40% map/ 11.10 mae\n",
      "33/38\n",
      "500 features, 23.99% map/ 4.08 mae\n",
      "34/38\n",
      "600 features, 17.72% map/ 2.80 mae\n",
      "35/38\n",
      "700 features, 17.08% map/ 2.98 mae\n",
      "36/38\n",
      "800 features, 15.07% map/ 2.71 mae\n",
      "37/38\n",
      "900 features, 13.89% map/ 2.55 mae\n",
      "38/38\n",
      "1100 features, 14.30% map/ 2.64 mae\n"
     ]
    }
   ],
   "source": [
    "n_features = [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18, 20, 24, 28, 32, 35, 40, 45, 50, 55, 60,\n",
    "      70, 80, 90, 100, 150, 200, 250, 300, 400, 500, 600, 700, 800, 900, 1100]\n",
    "mae_err, map_err = grid_search(df_X,df_Y,n_features=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = np.array(mae_err)\n",
    "np.save(\"corr_fit_results\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
