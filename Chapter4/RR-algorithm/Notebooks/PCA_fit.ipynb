{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pierre-Paul\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Pierre-Paul\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import multiprocessing as mp\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.read_pickle('df_S300_featurized')\n",
    "df = df.replace([np.inf, -np.inf, np.nan], 0)\n",
    "df_X = df.drop('Input Data|S_300_atom',axis=1)\n",
    "a = {}\n",
    "for x in df_X.columns:\n",
    "    if 'ChemEnvSiteFingerprint|GaussianSymmFunc' in x:\n",
    "        a[x] = 'GaussianSymmFunc|'+x[39:]\n",
    "df_X = df_X.rename(a,axis=1)\n",
    "\n",
    "df_Y = df[['Input Data|S_300_atom']]\n",
    "\n",
    "#df_X=(df_X-df_X.min())/(df_X.max()-df_X.min())\n",
    "#df_Y=(df_Y-df_Y.min())/(df_Y.max()-df_Y.min())\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x_scaled = StandardScaler().fit_transform(df_X)\n",
    "df_X = pd.DataFrame(data=x_scaled,columns = df_X.columns,index = df_X.index)\n",
    "\n",
    "df_X = df_X.replace([np.inf, -np.inf, np.nan], 0)\n",
    "\n",
    "def get_features(n):\n",
    "\n",
    "    return [\"pls {}\".format(i+1) for i in range(n)]\n",
    "\n",
    "def CV_NN(model,df_X,df_Y,n_feat,cv=5,epochs=200,batch_size=100,plot = False):\n",
    "  df_X,df_Y = shuffle(df_X,df_Y)\n",
    "  size = df_X.shape[0]\n",
    "  mae_score = np.zeros(cv)\n",
    "  map_score = np.zeros(cv)\n",
    "  \n",
    "  weights = model.get_weights()\n",
    "  \n",
    "  for i in range(cv):\n",
    "        \n",
    "    df_X_val = df_X.iloc[:size//cv,:]\n",
    "    idx = df_X_val.index\n",
    "    df_X = df_X.drop(idx,axis=0)\n",
    "    df_Y_val = df_Y.loc[idx,:]\n",
    "    df_Y = df_Y.drop(idx,axis=0)\n",
    "        \n",
    "    pca = PCA(n_components=n_feat)\n",
    "    pca.fit(df_X.values)\n",
    "    x_train = pca.transform(df_X.values)\n",
    "    x_val = pca.transform(df_X_val)\n",
    "\n",
    "    \n",
    "    fit_params = {\n",
    "            'x': x_train,\n",
    "            'y': df_Y.values,\n",
    "            'epochs': epochs,\n",
    "            'batch_size': batch_size,\n",
    "            'verbose': 0,\n",
    "            'validation_data': (x_val,df_Y_val.values)\n",
    "            #'validation_freq': 2\n",
    "    }\n",
    "    \n",
    "    model.set_weights(weights)\n",
    "    history = model.fit(**fit_params)\n",
    "    mae =  history.history['mean_absolute_error']\n",
    "    val_map = history.history['val_mean_absolute_percentage_error']\n",
    "    val_mae = history.history['val_mean_absolute_error']   \n",
    "    score = np.sort(val_mae)[:40].mean()\n",
    "    score_p = np.sort(val_map)[:40].mean()\n",
    "    #score = np.array(val_mae[-40:]).mean()\n",
    "    #score_p = np.array(val_map[-40:]).mean()\n",
    "    mae_score[i] = score\n",
    "    map_score[i] = score_p\n",
    "    \n",
    "    df_X = df_X.append(df_X_val)\n",
    "    df_Y = df_Y.append(df_Y_val)\n",
    "    \n",
    "    if plot:\n",
    "      fig, ax = plt.subplots(figsize=(6,6))\n",
    "      ax.plot(mae,label='mae')\n",
    "      ax.plot(val_mae,label='val_mae')\n",
    "      # ax.set_ylim([0,6])\n",
    "      ax.set_title('entropy @ 300K')\n",
    "      ax.set_ylabel('MAE [J/Kmol]')\n",
    "      ax.set_ylabel('epochs')\n",
    "      ax.legend()\n",
    "      #fig.savefig(\"e{}.jpg\".format(str(T)))\n",
    "      ax.grid()\n",
    "      \n",
    "  return (mae_score.mean(), map_score.mean())\n",
    "\n",
    "def gen_model(n_features,bias=2):\n",
    "    f_input = Input(shape=(n_features,))\n",
    "    hidden1 = Dense(int(n_features/2)+bias,activation='relu')(f_input)\n",
    "    #hidden2 = Dense(int(n_features/2)+2,activation='relu')(hidden1)\n",
    "    out = Dense(1,activation='linear')(hidden1) #output is bounded below\n",
    "    model = keras.models.Model(f_input,out)\n",
    "    model.compile(loss = 'mae', metrics=['mae','mean_absolute_percentage_error'],\n",
    "                  optimizer=keras.optimizers.Adam(0.01))\n",
    "    return model\n",
    "  \n",
    "    \n",
    "def grid_search(df_X,df_Y,n_features):\n",
    "    iterations = len(n_features)\n",
    "    i=1\n",
    "    mae_score = []\n",
    "    map_score = []\n",
    "    for n in n_features:\n",
    "        print('{}/{}'.format(i,iterations))\n",
    "        model = gen_model(n,bias=16)\n",
    "        best_score, best_scorep = CV_NN(model,df_X,df_Y,n)\n",
    "        print(\"{} features, {:.2f}% map/ {:.2f} mae\".format(n,best_scorep,best_score))\n",
    "        mae_score += [best_score]\n",
    "        map_score += [best_scorep]\n",
    "        i+=1\n",
    "    return (mae_score,map_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/38\n",
      "WARNING:tensorflow:From C:\\Users\\Pierre-Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Pierre-Paul\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "2 features, 58.38% map/ 9.13 mae\n",
      "2/38\n",
      "3 features, 39.85% map/ 7.25 mae\n",
      "3/38\n",
      "4 features, 37.14% map/ 6.60 mae\n",
      "4/38\n",
      "5 features, 34.65% map/ 6.20 mae\n",
      "5/38\n",
      "6 features, 32.07% map/ 5.92 mae\n",
      "6/38\n",
      "7 features, 31.08% map/ 5.72 mae\n",
      "7/38\n",
      "8 features, 30.27% map/ 5.64 mae\n",
      "8/38\n",
      "9 features, 30.35% map/ 5.75 mae\n",
      "9/38\n",
      "10 features, 29.00% map/ 5.39 mae\n",
      "10/38\n",
      "12 features, 29.64% map/ 5.03 mae\n",
      "11/38\n",
      "14 features, 28.24% map/ 4.94 mae\n",
      "12/38\n",
      "16 features, 26.82% map/ 4.69 mae\n",
      "13/38\n",
      "18 features, 25.49% map/ 4.59 mae\n",
      "14/38\n",
      "20 features, 25.64% map/ 4.55 mae\n",
      "15/38\n",
      "24 features, 25.43% map/ 4.41 mae\n",
      "16/38\n",
      "28 features, 24.57% map/ 4.40 mae\n",
      "17/38\n",
      "32 features, 23.97% map/ 4.26 mae\n",
      "18/38\n",
      "35 features, 25.10% map/ 4.15 mae\n",
      "19/38\n",
      "40 features, 24.26% map/ 4.21 mae\n",
      "20/38\n",
      "45 features, 23.17% map/ 4.20 mae\n",
      "21/38\n",
      "50 features, 23.66% map/ 4.24 mae\n",
      "22/38\n",
      "55 features, 22.96% map/ 4.16 mae\n",
      "23/38\n",
      "60 features, 24.21% map/ 4.12 mae\n",
      "24/38\n",
      "70 features, 22.35% map/ 4.11 mae\n",
      "25/38\n",
      "80 features, 21.72% map/ 4.08 mae\n",
      "26/38\n",
      "90 features, 21.51% map/ 3.95 mae\n",
      "27/38\n",
      "100 features, 21.08% map/ 4.05 mae\n",
      "28/38\n",
      "150 features, 20.79% map/ 4.04 mae\n",
      "29/38\n",
      "200 features, 21.30% map/ 4.16 mae\n",
      "30/38\n",
      "250 features, 19.98% map/ 3.96 mae\n",
      "31/38\n",
      "300 features, 20.25% map/ 4.00 mae\n",
      "32/38\n",
      "400 features, 20.43% map/ 3.96 mae\n",
      "33/38\n",
      "500 features, 20.99% map/ 4.04 mae\n",
      "34/38\n",
      "600 features, 20.65% map/ 3.95 mae\n",
      "35/38\n",
      "700 features, 19.55% map/ 3.73 mae\n",
      "36/38\n",
      "800 features, 18.72% map/ 3.42 mae\n",
      "37/38\n",
      "900 features, 20.13% map/ 3.62 mae\n",
      "38/38\n",
      "996 features, 20.21% map/ 3.60 mae\n"
     ]
    }
   ],
   "source": [
    "n_features = [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18, 20, 24, 28, 32, 35, 40, 45, 50, 55, 60,\n",
    "      70, 80, 90, 100, 150, 200, 250, 300, 400, 500, 600, 700, 800, 900, 996]\n",
    "mae_err, map_err = grid_search(df_X,df_Y,n_features=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = np.array(mae_err)\n",
    "np.save(\"pca_fit_results\",err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
